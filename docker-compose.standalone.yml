# Standalone Docker Compose for Devstral OpenHands Deployment
# This file runs the entire application using the custom Dockerfile

version: '3.8'

services:
  devstral-deployment:
    build: .
    container_name: devstral-openhands-deployment
    privileged: true  # Required for Docker-in-Docker
    user: root  # Explicitly run as root to avoid permission issues
    environment:
      # Deployment Configuration
      - DEPLOYMENT_TYPE=${DEPLOYMENT_TYPE:-ollama}
      - MODEL_FILE=${MODEL_FILE:-devstral-model.gguf}
      - MODEL_NAME=${MODEL_NAME:-devstral}
      
      # Performance Settings
      - CONTEXT_SIZE=${CONTEXT_SIZE:-4096}
      - THREADS=${THREADS:-8}
      - BATCH_SIZE=${BATCH_SIZE:-512}
      - GPU_LAYERS=${GPU_LAYERS:-0}
      - GPU_ENABLED=${GPU_ENABLED:-false}
      
      # Port Configuration (internal ports)
      - OPENHANDS_PORT=3000
      - MODEL_SERVER_PORT=11434
      - WEBUI_PORT=8080
      - API_PORT=5000
      
      # Paths
      - WORKSPACE_PATH=./workspace
      - MODELS_PATH=./models
      
      # Docker environment variables to avoid ip6tables errors
      - DOCKER_OPTS="--ipv6=false --iptables=false --bridge=none"
    ports:
      - "${OPENHANDS_PORT:-12000}:3000"       # OpenHands web interface
      - "${MODEL_SERVER_PORT:-12001}:11434"   # Model API server
      - "${WEBUI_PORT:-8080}:8080"            # Web UI (Ollama/TextGen)
      - "${API_PORT:-5000}:5000"              # Additional API port
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock  # Docker socket for DinD
      - ./models:/app/models                       # Model files
      - ./workspace:/app/workspace                 # OpenHands workspace
      - ./logs:/app/logs                           # Application logs
      - devstral_data:/app/data                    # Persistent data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000"] 
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    # Improved Docker settings to avoid permission issues
    cap_add:
      - SYS_ADMIN
      - NET_ADMIN
      - NET_RAW    # Added for network bridge operations
    security_opt:
      - apparmor:unconfined
      - seccomp:unconfined  # Added for better container compatibility
    sysctls:
      - net.ipv4.ip_forward=1
      - net.ipv6.conf.all.disable_ipv6=1  # Completely disable IPv6
    tmpfs:
      - /tmp:exec,mode=777  # Use tmpfs for better performance and avoiding disk permission issues

# Create network explicitly
networks:
  default:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16  # Fixed subnet to avoid conflicts

volumes:
  devstral_data:

# Usage Examples:
#
# 1. Basic startup with Ollama (default):
#    docker-compose -f docker-compose.standalone.yml up -d
#
# 2. Use Text Generation WebUI:
#    DEPLOYMENT_TYPE=textgen docker-compose -f docker-compose.standalone.yml up -d
#
# 3. Use llama.cpp with GPU:
#    DEPLOYMENT_TYPE=llamacpp GPU_ENABLED=true GPU_LAYERS=35 docker-compose -f docker-compose.standalone.yml up -d
#
# 4. Custom model file:
#    MODEL_FILE=my-custom-model.gguf docker-compose -f docker-compose.standalone.yml up -d
#
# 5. Custom ports:
#    OPENHANDS_PORT=3000 MODEL_SERVER_PORT=8080 docker-compose -f docker-compose.standalone.yml up -d